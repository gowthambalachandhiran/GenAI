{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Forrest Fire (Protugal) prediction using SVR, Random Forest, and Deep NN\n",
    "\n",
    "This dataset is public available for research. The details are described in [Cortez and Morais, 2007]. Please include this citation if you plan to use this database:\n",
    "\n",
    "P. Cortez and A. Morais. ***A Data Mining Approach to Predict Forest Fires using Meteorological Data.*** \n",
    "In J. Neves, M. F. Santos and J. Machado Eds., New Trends in Artificial Intelligence, Proceedings of the 13th EPIA 2007 - Portuguese Conference on Artificial Intelligence, December, Guimaraes, Portugal, pp. 512-523, 2007. APPIA, ISBN-13 978-989-95618-0-9. \n",
    "  \n",
    "Available at: http://www.dsi.uminho.pt/~pcortez/fires.pdf\n",
    "\n",
    "For more information, read [Cortez and Morais, 2007].\n",
    "\n",
    "* X - x-axis spatial coordinate within the Montesinho park map: 1 to 9\n",
    "* Y - y-axis spatial coordinate within the Montesinho park map: 2 to 9\n",
    "* month - month of the year: \"jan\" to \"dec\" \n",
    "* day - day of the week: \"mon\" to \"sun\"\n",
    "* FFMC - FFMC index from the FWI system: 18.7 to 96.20\n",
    "* DMC - DMC index from the FWI system: 1.1 to 291.3 \n",
    "* DC - DC index from the FWI system: 7.9 to 860.6 \n",
    "* ISI - ISI index from the FWI system: 0.0 to 56.10\n",
    "* temp - temperature in Celsius degrees: 2.2 to 33.30\n",
    "* RH - relative humidity in %: 15.0 to 100\n",
    "* wind - wind speed in km/h: 0.40 to 9.40 \n",
    "* rain - outside rain in mm/m2 : 0.0 to 6.4 \n",
    "* area - the burned area of the forest (in ha): 0.00 to 1090.84\n",
    "\n",
    "**As we will see this is a extremely hard regression problem with clear outliers which cannot be predicted using any reasonable method. Four methods: (a) support vector regression, (b) decision tree, (c) random forest, (d) 3-layer dense neural network will be tried to show the relative performance.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read the Forest Fire dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('forestfires.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic statistics and visualization of the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Describe the statistics of numerical columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### Plot scatterplots and distributions of numerical features to see how they may affect the output 'area'\n",
    "\n",
    "For this, first we need to transform the outcome 'area' by taking its logarithm (after adding 1 to avoid zeros)\n",
    "\n",
    "$$\\text{Log-area} = log_{10}(area+1)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df['Log-area']=np.log10(df['area']+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for i in df.describe().columns[:-2]:\n",
    "    df.plot.scatter(i,'Log-area',grid=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot boxplots of how the categorical features (month and day) affect the outcome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.boxplot(column='Log-area',by='day')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.boxplot(column='Log-area',by='month')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data pre-processing, test/train split, REC function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Label encoder for the categorical feature (_day_ and _month_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc = LabelEncoder()\n",
    "enc.fit(df['month'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['month_encoded']=enc.transform(df['month'])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc.fit(df['day'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['day_encoded']=enc.transform(df['day'])\n",
    "df.head(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test set fraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_size=0.4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test/train split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_data=df.drop(['area','Log-area','month','day'],axis=1)\n",
    "y_data=df['Log-area']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_data, y_data, test_size=test_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train=y_train.values.reshape(y_train.size, 1)\n",
    "y_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regression Error Characteristic (REC) estimation\n",
    "\n",
    "Receiver Operating Characteristic (ROC) curves provide a powerful tool for visualizing and comparing classification results. Regression Error Characteristic (REC) curves generalize ROC curves to regression. REC curves plot the error tolerance on the $x-axis$ versus the percentage of points predicted within the tolerance on the $y-axis$. The resulting\n",
    "curve estimates the cumulative distribution function of the error. The REC curve visually presents commonly-useds tatistics. The area-over-the-curve (AOC) is a biased estimate of the expected error. The $R^2$ value can be estimated using the ratio of the AOC for a given model to the AOC for the nul-model. Users can quickly assess the relative\n",
    "merits of many regression functions by examining the relative position of their REC curves. The shape of the curve reveals additional information that can be used to guide modeling.\n",
    "\n",
    "[Check this paper for more details](https://www.aaai.org/Papers/ICML/2003/ICML03-009.pdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def rec(m,n,tol):\n",
    "    if type(m)!='numpy.ndarray':\n",
    "        m=np.array(m)\n",
    "    if type(n)!='numpy.ndarray':\n",
    "        n=np.array(n)\n",
    "    l=m.size\n",
    "    percent = 0\n",
    "    for i in range(l):\n",
    "        if np.abs(10**m[i]-10**n[i])<=tol:\n",
    "            percent+=1\n",
    "    return 100*(percent/l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define the max tolerance limit for REC curve x-axis\n",
    "# For this problem this represents the absolute value of error in the prediction of the outcome i.e. area burned\n",
    "tol_max=20"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gridsearch\n",
    "\n",
    "Finding the right parameters  for machine learning models is a tricky task! But luckily, Scikit-learn has the functionality of trying a bunch of combinations and see what works best, built in with GridSearchCV! The CV stands for cross-validation.\n",
    "\n",
    "**GridSearchCV takes a dictionary that describes the parameters that should be tried and a model to train. The grid of parameters is defined as a dictionary, where the keys are the parameters and the values are the settings to be tested.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Support Vector Regressor (SVR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.svm import SVR\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Parameter grid for the Grid Search\n",
    "param_grid = {'C': [0.01,0.1,1, 10], 'epsilon': [10,1,0.1,0.01,0.001,0.0001], 'kernel': ['rbf']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_SVR = GridSearchCV(SVR(),param_grid,refit=True,verbose=0,cv=5)\n",
    "grid_SVR.fit(scaler.fit_transform(X_train),scaler.fit_transform(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Best parameters obtained by Grid Search:\",grid_SVR.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=grid_SVR.predict(X_test)\n",
    "print(\"RMSE for Support Vector Regression:\",np.sqrt(np.mean((y_test-a)**2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.xlabel(\"Actual area burned\")\n",
    "plt.ylabel(\"Error\")\n",
    "plt.grid(True)\n",
    "plt.scatter(10**(y_test),10**(a)-10**(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.title(\"Histogram of prediction errors\\n\",fontsize=18)\n",
    "plt.xlabel(\"Prediction error ($ha$)\",fontsize=14)\n",
    "plt.grid(True)\n",
    "plt.hist(10**(a.reshape(a.size,))-10**(y_test),bins=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rec_SVR=[]\n",
    "for i in range(tol_max):\n",
    "    rec_SVR.append(rec(a,y_test,i))\n",
    "\n",
    "plt.figure(figsize=(5,5))\n",
    "plt.title(\"REC curve for the Support Vector Regressor\\n\",fontsize=15)\n",
    "plt.xlabel(\"Absolute error (tolerance) in prediction ($ha$)\")\n",
    "plt.ylabel(\"Percentage of correct prediction\")\n",
    "plt.xticks([i*5 for i in range(tol_max+1)])\n",
    "plt.ylim(-10,100)\n",
    "plt.yticks([i*20 for i in range(6)])\n",
    "plt.grid(True)\n",
    "plt.plot(range(tol_max),rec_SVR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_model = DecisionTreeRegressor(max_depth=10,criterion='absolute_error')\n",
    "tree_model.fit(scaler.fit_transform(X_train),scaler.fit_transform(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=tree_model.predict(X_test)\n",
    "print(\"RMSE for Decision Tree:\",np.sqrt(np.mean((y_test-a)**2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.xlabel(\"Actual area burned\")\n",
    "plt.ylabel(\"Error\")\n",
    "plt.grid(True)\n",
    "plt.scatter(10**(y_test),10**(a)-10**(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.title(\"Histogram of prediction errors\\n\",fontsize=18)\n",
    "plt.xlabel(\"Prediction error ($ha$)\",fontsize=14)\n",
    "plt.grid(True)\n",
    "plt.hist(10**(a.reshape(a.size,))-10**(y_test),bins=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rec_DT=[]\n",
    "for i in range(tol_max):\n",
    "    rec_DT.append(rec(a,y_test,i))\n",
    "\n",
    "plt.figure(figsize=(5,5))\n",
    "plt.title(\"REC curve for the single Decision Tree\\n\",fontsize=15)\n",
    "plt.xlabel(\"Absolute error (tolerance) in prediction ($ha$)\")\n",
    "plt.ylabel(\"Percentage of correct prediction\")\n",
    "plt.xticks([i for i in range(0,tol_max+1,5)])\n",
    "plt.ylim(-10,100)\n",
    "plt.yticks([i*20 for i in range(6)])\n",
    "plt.grid(True)\n",
    "plt.plot(range(tol_max),rec_DT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {'max_depth': [5,10,15,20,50], 'max_leaf_nodes': [2,5,10], 'min_samples_leaf': [2,5,10],\n",
    "             'min_samples_split':[2,5,10]}\n",
    "grid_RF = GridSearchCV(RandomForestRegressor(),param_grid,refit=True,verbose=0,cv=5)\n",
    "grid_RF.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Best parameters obtained by Grid Search:\",grid_RF.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=grid_RF.predict(X_test)\n",
    "rmse_rf=np.sqrt(np.mean((y_test-a)**2))\n",
    "print(\"RMSE for Random Forest:\",rmse_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.xlabel(\"Actual area burned\")\n",
    "plt.ylabel(\"Error\")\n",
    "plt.grid(True)\n",
    "plt.scatter(10**(y_test),10**(a)-10**(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.title(\"Histogram of prediction errors\\n\",fontsize=18)\n",
    "plt.xlabel(\"Prediction error ($ha$)\",fontsize=14)\n",
    "plt.grid(True)\n",
    "plt.hist(10**(a.reshape(a.size,))-10**(y_test),bins=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rec_RF=[]\n",
    "for i in range(tol_max):\n",
    "    rec_RF.append(rec(a,y_test,i))\n",
    "\n",
    "plt.figure(figsize=(5,5))\n",
    "plt.title(\"REC curve for the Random Forest\\n\",fontsize=15)\n",
    "plt.xlabel(\"Absolute error (tolerance) in prediction ($ha$)\")\n",
    "plt.ylabel(\"Percentage of correct prediction\")\n",
    "plt.xticks([i for i in range(0,tol_max+1,5)])\n",
    "plt.ylim(-10,100)\n",
    "plt.yticks([i*20 for i in range(6)])\n",
    "plt.grid(True)\n",
    "plt.plot(range(tol_max),rec_RF)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deep network (using Keras (_TensorFlow_ backend))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "import keras.optimizers as opti\n",
    "from keras.layers import Dense, Activation,Dropout"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(100, input_dim=12))\n",
    "model.add(Activation('selu'))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(100))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Activation('selu'))\n",
    "model.add(Dense(50))\n",
    "model.add(Activation('elu'))\n",
    "model.add(Dense(1))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Learning rate and optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "learning_rate=0.001\n",
    "optimizer = opti.RMSprop(learning_rate=learning_rate)\n",
    "model.compile(optimizer=optimizer,loss='mse')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Input data and mode fitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=X_train\n",
    "target = y_train\n",
    "model.fit(data, target, epochs=100, batch_size=10,verbose=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prediction and RMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=model.predict(X_test)\n",
    "print(\"RMSE for Deep Network:\",np.sqrt(np.mean((y_test-a.reshape(a.size,))**2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.xlabel(\"Actual area burned\")\n",
    "plt.ylabel(\"Error\")\n",
    "plt.grid(True)\n",
    "plt.scatter(10**(y_test),10**(a.reshape(a.size,))-10**(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.title(\"Histogram of prediction errors\\n\",fontsize=18)\n",
    "plt.xlabel(\"Prediction error ($ha$)\",fontsize=14)\n",
    "plt.grid(True)\n",
    "plt.hist(10**(a.reshape(a.size,))-10**(y_test),bins=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rec_NN=[]\n",
    "for i in range(tol_max):\n",
    "    rec_NN.append(rec(a,y_test,i))\n",
    "\n",
    "plt.figure(figsize=(5,5))\n",
    "plt.title(\"REC curve for the Deep Network\\n\",fontsize=15)\n",
    "plt.xlabel(\"Absolute error (tolerance) in prediction ($ha$)\")\n",
    "plt.ylabel(\"Percentage of correct prediction\")\n",
    "plt.xticks([i for i in range(0,tol_max+1,5)])\n",
    "plt.ylim(-10,100)\n",
    "plt.yticks([i*20 for i in range(6)])\n",
    "plt.grid(True)\n",
    "plt.plot(range(tol_max),rec_NN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Relative performance of various models (REC curves)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,8))\n",
    "plt.title(\"REC curve for various models\\n\",fontsize=20)\n",
    "plt.xlabel(\"Absolute error (tolerance) in prediction ($ha$)\",fontsize=15)\n",
    "plt.ylabel(\"Percentage of correct prediction\",fontsize=15)\n",
    "plt.xticks([i for i in range(0,tol_max+1,1)],fontsize=13)\n",
    "plt.ylim(-10,100)\n",
    "plt.xlim(-2,tol_max)\n",
    "plt.yticks([i*20 for i in range(6)],fontsize=18)\n",
    "plt.grid(True)\n",
    "plt.plot(range(tol_max),rec_SVR,'--',lw=3)\n",
    "plt.plot(range(tol_max),rec_DT,'*-',lw=3)\n",
    "plt.plot(range(tol_max),rec_RF,'o-',lw=3)\n",
    "plt.plot(range(tol_max),rec_NN,'k-',lw=3)\n",
    "plt.legend(['SVR','Decision Tree','Random Forest','Deep NN'],fontsize=13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "da5401",
   "language": "python",
   "name": "da5401"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
