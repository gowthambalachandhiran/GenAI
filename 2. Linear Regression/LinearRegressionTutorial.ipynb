{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29aee909",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-27T14:03:11.953882Z",
     "start_time": "2024-08-27T14:03:10.963651Z"
    },
    "execution": {
     "iopub.execute_input": "2024-08-25T15:23:49.250906Z",
     "iopub.status.busy": "2024-08-25T15:23:49.250703Z",
     "iopub.status.idle": "2024-08-25T15:23:50.191231Z",
     "shell.execute_reply": "2024-08-25T15:23:50.190588Z",
     "shell.execute_reply.started": "2024-08-25T15:23:49.250890Z"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from math import log\n",
    "from sklearn import linear_model\n",
    "\n",
    "#comment below if not using ipython notebook\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f50ffeb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-27T14:03:14.119585Z",
     "start_time": "2024-08-27T14:03:11.955612Z"
    },
    "execution": {
     "iopub.execute_input": "2024-08-25T15:23:50.192406Z",
     "iopub.status.busy": "2024-08-25T15:23:50.192157Z",
     "iopub.status.idle": "2024-08-25T15:23:51.821996Z",
     "shell.execute_reply": "2024-08-25T15:23:51.821341Z",
     "shell.execute_reply.started": "2024-08-25T15:23:50.192389Z"
    }
   },
   "outputs": [],
   "source": [
    "#!pip -q install visualkeras\n",
    "import visualkeras"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c84274da",
   "metadata": {},
   "source": [
    "### let's load the data into a dataframe\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac2aa1f2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-27T14:03:14.127744Z",
     "start_time": "2024-08-27T14:03:14.120598Z"
    },
    "execution": {
     "iopub.execute_input": "2024-08-25T15:23:51.822942Z",
     "iopub.status.busy": "2024-08-25T15:23:51.822645Z",
     "iopub.status.idle": "2024-08-25T15:23:51.832615Z",
     "shell.execute_reply": "2024-08-25T15:23:51.832202Z",
     "shell.execute_reply.started": "2024-08-25T15:23:51.822925Z"
    }
   },
   "outputs": [],
   "source": [
    "data  = pd.read_csv('Assignment2.data', sep='\\t')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63f4d796",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-27T14:03:14.136048Z",
     "start_time": "2024-08-27T14:03:14.128983Z"
    },
    "execution": {
     "iopub.execute_input": "2024-08-25T15:23:51.833728Z",
     "iopub.status.busy": "2024-08-25T15:23:51.833565Z",
     "iopub.status.idle": "2024-08-25T15:23:51.842986Z",
     "shell.execute_reply": "2024-08-25T15:23:51.842600Z",
     "shell.execute_reply.started": "2024-08-25T15:23:51.833714Z"
    }
   },
   "outputs": [],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a494dbc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-27T14:03:14.251899Z",
     "start_time": "2024-08-27T14:03:14.136845Z"
    },
    "execution": {
     "iopub.execute_input": "2024-08-25T15:23:51.843649Z",
     "iopub.status.busy": "2024-08-25T15:23:51.843491Z",
     "iopub.status.idle": "2024-08-25T15:23:52.005729Z",
     "shell.execute_reply": "2024-08-25T15:23:52.005123Z",
     "shell.execute_reply.started": "2024-08-25T15:23:51.843635Z"
    }
   },
   "outputs": [],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(2, 1)\n",
    "fig.suptitle('Two Cyber Physical Systems')\n",
    "fig.set_figwidth(10)\n",
    "fig.set_figheight(5)\n",
    "\n",
    "ax1.plot(data.SpringPos, 'r+')\n",
    "ax1.set_ylabel('Spring Position')\n",
    "ax2.plot(data.StockPrice, 'b.')\n",
    "ax2.set_ylabel('Stock Price')\n",
    "ax2.set_xlabel('time')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3008fd8",
   "metadata": {},
   "source": [
    "## Fit a linear model on the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87e432a7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-27T14:03:14.257462Z",
     "start_time": "2024-08-27T14:03:14.252761Z"
    },
    "execution": {
     "iopub.execute_input": "2024-08-25T15:23:52.006777Z",
     "iopub.status.busy": "2024-08-25T15:23:52.006568Z",
     "iopub.status.idle": "2024-08-25T15:23:52.012697Z",
     "shell.execute_reply": "2024-08-25T15:23:52.012337Z",
     "shell.execute_reply.started": "2024-08-25T15:23:52.006762Z"
    }
   },
   "outputs": [],
   "source": [
    "y2 = pd.DataFrame({\"x\":range(226), \"y\":data.StockPrice})\n",
    "y2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e0826b7",
   "metadata": {},
   "source": [
    "### transform the data into matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8252b4cb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-27T14:03:14.261152Z",
     "start_time": "2024-08-27T14:03:14.258704Z"
    },
    "execution": {
     "iopub.execute_input": "2024-08-25T15:23:52.013481Z",
     "iopub.status.busy": "2024-08-25T15:23:52.013245Z",
     "iopub.status.idle": "2024-08-25T15:23:52.023818Z",
     "shell.execute_reply": "2024-08-25T15:23:52.023450Z",
     "shell.execute_reply.started": "2024-08-25T15:23:52.013467Z"
    }
   },
   "outputs": [],
   "source": [
    "yy = np.array(y2.y) \n",
    "xx = np.expand_dims(y2.x, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce9a84dc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-11T07:18:05.170375Z",
     "start_time": "2024-08-11T07:18:05.166742Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cc84a198",
   "metadata": {},
   "source": [
    "### run the closed form solution to estimate the beta parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e35f630",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-27T14:03:14.267380Z",
     "start_time": "2024-08-27T14:03:14.262470Z"
    },
    "execution": {
     "iopub.execute_input": "2024-08-25T15:23:52.024532Z",
     "iopub.status.busy": "2024-08-25T15:23:52.024345Z",
     "iopub.status.idle": "2024-08-25T15:23:52.034029Z",
     "shell.execute_reply": "2024-08-25T15:23:52.033549Z",
     "shell.execute_reply.started": "2024-08-25T15:23:52.024519Z"
    }
   },
   "outputs": [],
   "source": [
    "numerator = np.matmul(np.transpose(xx), yy)\n",
    "denom = np.matmul(np.transpose(xx), xx)\n",
    "denom_inv = np.linalg.inv(denom)\n",
    "beta = np.matmul(denom_inv, numerator)\n",
    "print(\"Beta = \", beta[0])\n",
    "sse = np.sum((xx*beta[0] - np.expand_dims(yy,1))**2)\n",
    "print(\"SSE = \", sse)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41b917b1",
   "metadata": {},
   "source": [
    "### as we will be reusing the above procedure often, let's make it a function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82ddc577",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-27T14:03:14.272562Z",
     "start_time": "2024-08-27T14:03:14.268584Z"
    },
    "execution": {
     "iopub.execute_input": "2024-08-25T15:23:52.034960Z",
     "iopub.status.busy": "2024-08-25T15:23:52.034784Z",
     "iopub.status.idle": "2024-08-25T15:23:52.042615Z",
     "shell.execute_reply": "2024-08-25T15:23:52.042151Z",
     "shell.execute_reply.started": "2024-08-25T15:23:52.034946Z"
    }
   },
   "outputs": [],
   "source": [
    "# estimate the value of the beta vector assuming that X is made of independent features.\n",
    "def estimateBeta(X, y):\n",
    "    numerator = np.matmul(np.transpose(X), y)\n",
    "    denom = np.matmul(np.transpose(X), X)\n",
    "    denom_inv = np.linalg.inv(denom)\n",
    "    beta = np.matmul(denom_inv, numerator)\n",
    "    return beta\n",
    "\n",
    "# create a helper that would estimate yhat from X and beta.\n",
    "def predict(beta, X):\n",
    "    # reshape the input to a matrix, if it is appearing like an 1d array.\n",
    "    if len(X.shape) != 2:\n",
    "        X = np.expand_dims(X,1)\n",
    "    # convert the beta list in to an array.\n",
    "    beta = np.array(beta)\n",
    "    # perform estimation of yhat.\n",
    "    return np.matmul(X, beta)\n",
    "\n",
    "# compute the sum of squared error between y and yhat.\n",
    "def SSE(y, yhat):\n",
    "    return np.sum((y-yhat)**2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c89e0910",
   "metadata": {},
   "source": [
    "### Let's plot the raw data and the regression line on the same plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3cf8a09",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-27T14:03:14.343319Z",
     "start_time": "2024-08-27T14:03:14.275362Z"
    },
    "execution": {
     "iopub.execute_input": "2024-08-25T15:23:52.044390Z",
     "iopub.status.busy": "2024-08-25T15:23:52.044150Z",
     "iopub.status.idle": "2024-08-25T15:23:52.134974Z",
     "shell.execute_reply": "2024-08-25T15:23:52.134460Z",
     "shell.execute_reply.started": "2024-08-25T15:23:52.044375Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.plot(y2.x, y2.y, 'r+')\n",
    "yhat1 = predict(beta, y2.x)\n",
    "plt.plot(y2.x, yhat1, 'b-')  # yhat = y2.x*beta[0]\n",
    "plt.ylabel('Stock Price')\n",
    "plt.xlabel('Time')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "181854de",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-11T07:11:43.870023Z",
     "start_time": "2024-08-11T07:11:43.802765Z"
    }
   },
   "source": [
    "### let's add an intercept (bias) to the data and check if the SSE drops further."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "386b272b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-27T14:03:14.350440Z",
     "start_time": "2024-08-27T14:03:14.344286Z"
    },
    "execution": {
     "iopub.execute_input": "2024-08-25T15:23:52.135887Z",
     "iopub.status.busy": "2024-08-25T15:23:52.135711Z",
     "iopub.status.idle": "2024-08-25T15:23:52.143374Z",
     "shell.execute_reply": "2024-08-25T15:23:52.143019Z",
     "shell.execute_reply.started": "2024-08-25T15:23:52.135874Z"
    }
   },
   "outputs": [],
   "source": [
    "y2df = pd.DataFrame({\"bias\":np.ones(226), \"x\":range(226), \"y\":data.StockPrice})\n",
    "yy = np.array(y2df.y) \n",
    "xx = np.array(y2df[[\"bias\",\"x\"]])\n",
    "y2df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "223df185",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-11T07:15:37.075016Z",
     "start_time": "2024-08-11T07:15:37.071114Z"
    }
   },
   "source": [
    "### estimate the beta params and compute the loss again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce356d20",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-27T14:03:14.355012Z",
     "start_time": "2024-08-27T14:03:14.351672Z"
    },
    "execution": {
     "iopub.execute_input": "2024-08-25T15:23:52.144146Z",
     "iopub.status.busy": "2024-08-25T15:23:52.143892Z",
     "iopub.status.idle": "2024-08-25T15:23:52.149981Z",
     "shell.execute_reply": "2024-08-25T15:23:52.149575Z",
     "shell.execute_reply.started": "2024-08-25T15:23:52.144131Z"
    }
   },
   "outputs": [],
   "source": [
    "beta2 = estimateBeta(xx, yy)\n",
    "print(\"beta =\", beta2)\n",
    "yhat2 = predict(beta2, xx)\n",
    "loss = SSE(yy, yhat2)\n",
    "print(\"SSE =\", loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aae8b813",
   "metadata": {},
   "source": [
    "### interesting! the loss has dropped with a little bit on intercept.  Let's plot it side by side."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39ef5941",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-27T14:03:14.426396Z",
     "start_time": "2024-08-27T14:03:14.356087Z"
    },
    "execution": {
     "iopub.execute_input": "2024-08-25T15:23:52.150769Z",
     "iopub.status.busy": "2024-08-25T15:23:52.150511Z",
     "iopub.status.idle": "2024-08-25T15:23:52.236640Z",
     "shell.execute_reply": "2024-08-25T15:23:52.236232Z",
     "shell.execute_reply.started": "2024-08-25T15:23:52.150756Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.plot(y2df.x, y2df.y, 'r+')\n",
    "plt.plot(y2df.x, yhat1, 'b-')\n",
    "plt.plot(y2df.x, yhat2, 'g-')\n",
    "plt.ylabel('Stock Price')\n",
    "plt.xlabel('Time')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcf25ec8",
   "metadata": {},
   "source": [
    "### Let's model the periodicity\n",
    "\n",
    "Let's borrow the slope information from the fit to set up the scale of the time axis.\n",
    "\n",
    "Instead of using $x$ in integer scale, we shall use the floating point scale as $x_1 \\leftarrow \\beta_0 * x$\n",
    "\n",
    "Likewise, let's create a new data dimension to capture the periodicity as $x_2 \\leftarrow sin(x_1)$\n",
    "\n",
    "Based on the expanded feature space, now let's try to model $\\hat{y} = m_1 x_1 + m_2 x_2$, note that we don't have to use the intercept $c$ as our previous linear model passed through the origin.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74da73a6",
   "metadata": {},
   "source": [
    "### create a feature space appropriately"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "addf3914",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-27T14:03:14.434749Z",
     "start_time": "2024-08-27T14:03:14.427274Z"
    },
    "execution": {
     "iopub.execute_input": "2024-08-25T15:23:52.237362Z",
     "iopub.status.busy": "2024-08-25T15:23:52.237204Z",
     "iopub.status.idle": "2024-08-25T15:23:52.245817Z",
     "shell.execute_reply": "2024-08-25T15:23:52.245462Z",
     "shell.execute_reply.started": "2024-08-25T15:23:52.237349Z"
    }
   },
   "outputs": [],
   "source": [
    "x1 = round(y2.x*beta2[1],2)\n",
    "x2 = np.sin(x1)\n",
    "\n",
    "y21 = pd.DataFrame({\"bias\":np.ones(226),\"x\":range(226), \"x1\":x1, \"x2\":x2, \"y\":data.StockPrice})\n",
    "y21.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73b9ccf9",
   "metadata": {},
   "source": [
    "### create the data matrices from the data frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d312769",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-27T14:03:14.437988Z",
     "start_time": "2024-08-27T14:03:14.435618Z"
    },
    "execution": {
     "iopub.execute_input": "2024-08-25T15:23:52.246581Z",
     "iopub.status.busy": "2024-08-25T15:23:52.246343Z",
     "iopub.status.idle": "2024-08-25T15:23:52.251481Z",
     "shell.execute_reply": "2024-08-25T15:23:52.251106Z",
     "shell.execute_reply.started": "2024-08-25T15:23:52.246567Z"
    }
   },
   "outputs": [],
   "source": [
    "xx = np.array(y21[['bias', 'x1', 'x2']])\n",
    "yy = np.array(y2.y) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3da1206a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-27T14:03:14.442311Z",
     "start_time": "2024-08-27T14:03:14.438852Z"
    },
    "execution": {
     "iopub.execute_input": "2024-08-25T15:23:52.252198Z",
     "iopub.status.busy": "2024-08-25T15:23:52.252031Z",
     "iopub.status.idle": "2024-08-25T15:23:52.258929Z",
     "shell.execute_reply": "2024-08-25T15:23:52.258221Z",
     "shell.execute_reply.started": "2024-08-25T15:23:52.252184Z"
    }
   },
   "outputs": [],
   "source": [
    "beta3 = estimateBeta(xx, yy)\n",
    "print(\"Beta = \", beta3)\n",
    "yhat3 = predict(beta3, xx)\n",
    "loss = SSE(yy, yhat3) #np.sum((np.matmul(xx,beta) - yy)**2)\n",
    "print(\"SSE = \", loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d462bdc",
   "metadata": {},
   "source": [
    "### Let's plot the raw data and the regression line on the same plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "871af5b8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-27T14:03:14.514996Z",
     "start_time": "2024-08-27T14:03:14.443171Z"
    },
    "execution": {
     "iopub.execute_input": "2024-08-25T15:23:52.260274Z",
     "iopub.status.busy": "2024-08-25T15:23:52.259967Z",
     "iopub.status.idle": "2024-08-25T15:23:52.353231Z",
     "shell.execute_reply": "2024-08-25T15:23:52.352628Z",
     "shell.execute_reply.started": "2024-08-25T15:23:52.260249Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.plot(y2.x, y2.y, 'r+')\n",
    "plt.plot(y2.x, yhat3, 'b-')\n",
    "plt.ylabel('Stock Price')\n",
    "plt.xlabel('Time')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "779ef3c0",
   "metadata": {},
   "source": [
    "### we were able to see the sin(x) from the visual.  what if we can't visualize? let's try the polynomial fit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b025ff9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-27T14:03:14.522447Z",
     "start_time": "2024-08-27T14:03:14.515937Z"
    },
    "execution": {
     "iopub.execute_input": "2024-08-25T15:23:52.354018Z",
     "iopub.status.busy": "2024-08-25T15:23:52.353856Z",
     "iopub.status.idle": "2024-08-25T15:23:52.361906Z",
     "shell.execute_reply": "2024-08-25T15:23:52.361583Z",
     "shell.execute_reply.started": "2024-08-25T15:23:52.354004Z"
    }
   },
   "outputs": [],
   "source": [
    "x1 = round(y2.x*beta2[1],2)\n",
    "\n",
    "y21 = pd.DataFrame({\"bias\":np.ones(226),\"x\":range(226), \"x1\":x1, \"y\":data.StockPrice})\n",
    "y21.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "822ad6fc",
   "metadata": {},
   "source": [
    "### create the data matrices from the data frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b0fce3e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-27T14:03:14.525663Z",
     "start_time": "2024-08-27T14:03:14.523450Z"
    },
    "execution": {
     "iopub.execute_input": "2024-08-25T15:23:52.362597Z",
     "iopub.status.busy": "2024-08-25T15:23:52.362436Z",
     "iopub.status.idle": "2024-08-25T15:23:52.366657Z",
     "shell.execute_reply": "2024-08-25T15:23:52.366287Z",
     "shell.execute_reply.started": "2024-08-25T15:23:52.362583Z"
    }
   },
   "outputs": [],
   "source": [
    "# here we don't need the explicit bias feature column, as polynomial features would include it already (x^0 = 1)\n",
    "xx = np.array(y21[['x1']])\n",
    "yy = np.array(y2.y) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4347b0be",
   "metadata": {},
   "source": [
    "### let's use the polynomial features generator instead of manually doing it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04eb4141",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-27T14:03:14.529859Z",
     "start_time": "2024-08-27T14:03:14.526659Z"
    },
    "execution": {
     "iopub.execute_input": "2024-08-25T15:23:52.367329Z",
     "iopub.status.busy": "2024-08-25T15:23:52.367177Z",
     "iopub.status.idle": "2024-08-25T15:23:52.371843Z",
     "shell.execute_reply": "2024-08-25T15:23:52.371475Z",
     "shell.execute_reply.started": "2024-08-25T15:23:52.367316Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "poly_transformer = PolynomialFeatures(degree = 50)   # 10, 11\n",
    "X_poly = poly_transformer.fit_transform(xx)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4087aac",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-11T10:00:53.281808Z",
     "start_time": "2024-08-11T10:00:53.277419Z"
    }
   },
   "source": [
    "### fit the model and estimate the loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11e22d7c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-27T14:03:14.551924Z",
     "start_time": "2024-08-27T14:03:14.531393Z"
    },
    "execution": {
     "iopub.execute_input": "2024-08-25T15:23:52.372612Z",
     "iopub.status.busy": "2024-08-25T15:23:52.372369Z",
     "iopub.status.idle": "2024-08-25T15:23:52.381636Z",
     "shell.execute_reply": "2024-08-25T15:23:52.380527Z",
     "shell.execute_reply.started": "2024-08-25T15:23:52.372598Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "model = LinearRegression().fit(X_poly, yy)\n",
    "print(\"Intercept=\", model.intercept_, \"Beta = \", model.coef_)\n",
    "yhat4 = model.predict(X_poly)\n",
    "\n",
    "#beta4 = estimateBeta(X_poly, yy)\n",
    "#print(\"Beta = \", beta4)\n",
    "#yhat4 = predict(beta4, X_poly)\n",
    "\n",
    "loss = SSE(yy, yhat4)\n",
    "print(\"SSE = \", loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c445980e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-11T10:28:17.227856Z",
     "start_time": "2024-08-11T10:28:17.223470Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e6e0fcb2",
   "metadata": {},
   "source": [
    "### Let's plot the raw data and the regression line on the same plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03d784eb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-27T14:03:14.657608Z",
     "start_time": "2024-08-27T14:03:14.552986Z"
    },
    "execution": {
     "iopub.execute_input": "2024-08-25T15:23:52.382896Z",
     "iopub.status.busy": "2024-08-25T15:23:52.382692Z",
     "iopub.status.idle": "2024-08-25T15:23:52.517559Z",
     "shell.execute_reply": "2024-08-25T15:23:52.517219Z",
     "shell.execute_reply.started": "2024-08-25T15:23:52.382877Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.plot(y2.x, y2.y, 'r+')\n",
    "plt.plot(y2.x, yhat4, 'b-')\n",
    "plt.ylabel('Stock Price')\n",
    "plt.xlabel('Time')\n",
    "plt.legend(['Price', 'OLS'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf73e851",
   "metadata": {},
   "source": [
    "### Brilliant, how to I find the best degree automatically without performing a linear search!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cb24bc4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-27T14:03:15.193135Z",
     "start_time": "2024-08-27T14:03:14.658595Z"
    },
    "execution": {
     "iopub.execute_input": "2024-08-25T15:23:52.518269Z",
     "iopub.status.busy": "2024-08-25T15:23:52.518101Z",
     "iopub.status.idle": "2024-08-25T15:23:53.109630Z",
     "shell.execute_reply": "2024-08-25T15:23:53.108398Z",
     "shell.execute_reply.started": "2024-08-25T15:23:52.518256Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Lasso, Ridge\n",
    "model5 = Lasso(alpha=500, max_iter=50000).fit(X_poly, yy)\n",
    "#model5 = Ridge(alpha=5220).fit(X_poly,yy)\n",
    "print(\"Beta =\", model5.coef_)\n",
    "yhat5 = model5.predict(X_poly)\n",
    "loss = SSE(yy, yhat5)\n",
    "print(\"SSE =\", loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66c371d9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-27T14:03:15.337208Z",
     "start_time": "2024-08-27T14:03:15.194250Z"
    },
    "execution": {
     "iopub.execute_input": "2024-08-25T15:23:53.110468Z",
     "iopub.status.busy": "2024-08-25T15:23:53.110317Z",
     "iopub.status.idle": "2024-08-25T15:23:53.228862Z",
     "shell.execute_reply": "2024-08-25T15:23:53.228351Z",
     "shell.execute_reply.started": "2024-08-25T15:23:53.110455Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.ylabel('Stock Price')\n",
    "plt.xlabel('Time')\n",
    "plt.plot(y2.x, y2.y, 'r+')\n",
    "plt.plot(y2.x, yhat4, 'b-')\n",
    "plt.plot(y2.x, yhat5, 'g-')\n",
    "plt.plot(y2.x, yhat2, '--')\n",
    "plt.plot(y2.x, yhat3, 'k')\n",
    "plt.legend(['Stock Price', 'PolynomialFit', 'Poly+Lasso', 'LineFit', 'Line+Sinusoid'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "703b8c7c",
   "metadata": {},
   "source": [
    "### what if closed form is not possible?  Gradient descent comes to the rescue."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a90d0c42",
   "metadata": {},
   "source": [
    "Let's consider solving the LineFit problem in the Gradient Descent style.\n",
    "\n",
    "As long as our mathematical model of the system is differentiable (gradients are computable), our loss function $\\mathcal{L} = (y-\\hat{y})^2$ remains differentiable.\n",
    "\n",
    "Our linear model is given by $\\hat{y} = \\beta_0 + \\beta_1 x = X^\\top\\beta$ and the loss is given by $\\mathcal{L} = [y - (\\beta_0 + \\beta_1 x)]^2 = [y-X^\\top\\beta]^\\top[y-X^\\top\\beta]$\n",
    "\n",
    "The average loss gradients for the full dataset are given by $\\frac{\\partial\\mathcal{L}}{\\partial\\beta_0} = \\frac{-2}{N} \\sum (y-\\hat{y}) $ and $\\frac{\\partial\\mathcal{L}}{\\partial\\beta_1} = \\frac{-2}{N} \\sum X^\\top(y-\\hat{y})$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a707e62",
   "metadata": {},
   "source": [
    "### the GD algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cc8fa07",
   "metadata": {},
   "source": [
    "* Choose the mathematical model; ensure it's continuous and differentiable.\n",
    "* Initialize the model parameters to random numbers.  Usually they are sampled from standard normal distribution.\n",
    "* Compute the gradient of the loss based on the current model parametric setting.\n",
    "* Update the parameters using $\\beta_i \\leftarrow \\beta_i + \\eta \\frac{\\partial\\mathcal{L}}{\\partial\\beta_i}$\n",
    "* Repeat the last two steps until the loss minimizes to the required target or it reaches a plateau.  If the loss increases, you have done something incorrectly."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a60a8c5",
   "metadata": {},
   "source": [
    "### let's implement the gradient descent algorithm for the linefit solution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "348d6331",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-27T14:03:15.379617Z",
     "start_time": "2024-08-27T14:03:15.338147Z"
    },
    "execution": {
     "iopub.execute_input": "2024-08-25T15:23:53.229309Z",
     "iopub.status.busy": "2024-08-25T15:23:53.229219Z",
     "iopub.status.idle": "2024-08-25T15:23:53.259284Z",
     "shell.execute_reply": "2024-08-25T15:23:53.258917Z",
     "shell.execute_reply.started": "2024-08-25T15:23:53.229301Z"
    }
   },
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm\n",
    "\n",
    "class MyLineFitViaGD:\n",
    "    def __init__(self, learning_rate=0.0001, n_iters=10_000):\n",
    "        self.lr = learning_rate\n",
    "        self.n_iters = n_iters\n",
    "        self.weights = None\n",
    "        self.bias = None\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        n_samples, n_features = X.shape\n",
    "        # init parameters\n",
    "        self.weights = np.random.randn(n_features)\n",
    "        self.bias = np.random.randn(1)\n",
    "        # gradient descent\n",
    "        tq = tqdm(range(self.n_iters), desc=\"Iterations\")\n",
    "        for _ in  tq:\n",
    "            # approximate y with linear combination of weights and x, plus bias\n",
    "            y_predicted = np.matmul(X, self.weights) + self.bias\n",
    "\n",
    "            # compute the gap between true and predicted outputs.\n",
    "            diff = y_predicted - y\n",
    "            loss = np.sum(diff * diff)\n",
    "            \n",
    "            # compute gradients\n",
    "            dw = (1 / n_samples) * np.matmul(X.T, diff)\n",
    "            db = (1 / n_samples) * np.sum(diff)\n",
    "            # update parameters\n",
    "            self.weights  = self.weights - self.lr * dw\n",
    "            self.bias  = self.bias -  self.lr * db\n",
    "            \n",
    "            # display the loss on the progress bar.\n",
    "            tq.set_postfix({\"Loss\":loss})\n",
    "            \n",
    "    @property\n",
    "    def parameters(self):\n",
    "        return self.bias, self.weights\n",
    "            \n",
    "    def predict(self, X):\n",
    "        y_predicted = np.dot(X, self.weights) + self.bias\n",
    "        return y_predicted"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a3825c7",
   "metadata": {},
   "source": [
    "### recall our linear fit dataset and construct the dataset matrices again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b23c7bf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-27T14:03:15.383915Z",
     "start_time": "2024-08-27T14:03:15.380430Z"
    },
    "execution": {
     "iopub.execute_input": "2024-08-25T15:23:53.259885Z",
     "iopub.status.busy": "2024-08-25T15:23:53.259657Z",
     "iopub.status.idle": "2024-08-25T15:23:53.262970Z",
     "shell.execute_reply": "2024-08-25T15:23:53.262689Z",
     "shell.execute_reply.started": "2024-08-25T15:23:53.259875Z"
    }
   },
   "outputs": [],
   "source": [
    "print(y2df.head())\n",
    "yy = np.array(y2df.y) \n",
    "xx = np.array(y2df[[\"x\"]])  # no need for \"bias\", as our GD method factors it already."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "734c81b6",
   "metadata": {},
   "source": [
    "### let's now build the model via Gradient Descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb8f01bc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-27T14:03:16.023409Z",
     "start_time": "2024-08-27T14:03:15.384687Z"
    },
    "execution": {
     "iopub.execute_input": "2024-08-25T15:23:53.263383Z",
     "iopub.status.busy": "2024-08-25T15:23:53.263250Z",
     "iopub.status.idle": "2024-08-25T15:23:53.467586Z",
     "shell.execute_reply": "2024-08-25T15:23:53.467373Z",
     "shell.execute_reply.started": "2024-08-25T15:23:53.263376Z"
    }
   },
   "outputs": [],
   "source": [
    "gdmodel = MyLineFitViaGD(learning_rate=0.0000001, n_iters=5000)\n",
    "# fit the model and estimate the yhat values.\n",
    "gdmodel.fit(xx, yy)\n",
    "#get the learned parameters from the model.\n",
    "bias, weights = gdmodel.parameters\n",
    "print(\"Bias =\", bias, \" Weights =\", weights)\n",
    "# use the model to predict the yhat values.\n",
    "yhat6 = gdmodel.predict(xx)\n",
    "# estimate the loss again and display\n",
    "loss = SSE(yy, yhat6)\n",
    "print (\"Loss =\", loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf0c4725",
   "metadata": {},
   "source": [
    "### let's visualize and compare the linear fits estimated by OLS and GD."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "975e76b3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-27T14:03:16.110335Z",
     "start_time": "2024-08-27T14:03:16.032913Z"
    },
    "execution": {
     "iopub.execute_input": "2024-08-25T15:23:53.468718Z",
     "iopub.status.busy": "2024-08-25T15:23:53.468589Z",
     "iopub.status.idle": "2024-08-25T15:23:53.513547Z",
     "shell.execute_reply": "2024-08-25T15:23:53.513229Z",
     "shell.execute_reply.started": "2024-08-25T15:23:53.468710Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.plot(y2.x, y2.y, 'r+')\n",
    "yhat1 = predict(beta, y2.x)\n",
    "plt.plot(y2.x, yhat1, 'b-')\n",
    "plt.plot(y2.x, yhat6, 'g-')\n",
    "plt.ylabel('Stock Price')\n",
    "plt.xlabel('Time')\n",
    "plt.legend(['Stock Price', 'LineFit+OLS', 'LineFit+GD'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e6b7769",
   "metadata": {},
   "source": [
    "### let's try GD on our sinusoidal mathematical model\n",
    "\n",
    "Now, our mathematical model of system is given by $\\hat{y} = \\beta_0 + \\beta_1 x + \\beta_2\\sin(\\beta_3 x)$\n",
    "\n",
    "$\\frac{\\partial\\mathcal{L}}{\\partial\\beta_0} = \\frac{-2}{N} \\sum (y-\\hat{y})$\n",
    "\n",
    "$\\frac{\\partial\\mathcal{L}}{\\partial\\beta_1} = \\frac{-2}{N} \\sum X^\\top(y-\\hat{y})$\n",
    "\n",
    "$\\frac{\\partial\\mathcal{L}}{\\partial\\beta_2} = \\frac{-2}{N} \\sum \\sin(\\beta_3 X)^\\top(y-\\hat{y})$\n",
    "\n",
    "$\\frac{\\partial\\mathcal{L}}{\\partial\\beta_3} = \\frac{-2}{N} \\sum (\\beta_2\\cos(\\beta_3 X) \\cdot X)^\\top(y-\\hat{y})$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eee5ee3b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-27T14:03:16.117754Z",
     "start_time": "2024-08-27T14:03:16.111460Z"
    },
    "execution": {
     "iopub.execute_input": "2024-08-25T15:23:53.513962Z",
     "iopub.status.busy": "2024-08-25T15:23:53.513862Z",
     "iopub.status.idle": "2024-08-25T15:23:53.517841Z",
     "shell.execute_reply": "2024-08-25T15:23:53.517435Z",
     "shell.execute_reply.started": "2024-08-25T15:23:53.513955Z"
    }
   },
   "outputs": [],
   "source": [
    "class MySinusoidFitViaGD:\n",
    "    def __init__(self, learning_rate=0.0001, n_iters=10_000):\n",
    "        self.lr = learning_rate\n",
    "        self.n_iters = n_iters\n",
    "        # init parameters\n",
    "        self.m1 = np.abs(np.random.randn(1))\n",
    "        self.m2 = np.abs(np.random.randn(1))\n",
    "        # if I set this to random, convergence is not happening.  Choosing an initial value around 1.0 help convergence.\n",
    "        self.m3 = [1] #np.abs(np.random.randn(1))\n",
    "        self.bias = np.random.randn(1)\n",
    "        print(f\"Initial Params: Bias={self.bias[0]} M1={self.m1[0]}, M2={self.m2[0]}, M3={self.m3[0]}\")\n",
    "        \n",
    "    def fit(self, X, y):\n",
    "        n_samples, n_features = X.shape\n",
    "        # gradient descent\n",
    "        tq = tqdm(range(self.n_iters), desc=\"Iterations\")\n",
    "        # placeholder to capture the loss trend. \n",
    "        history = []\n",
    "\n",
    "        for _ in  tq:\n",
    "            # approximate y with linear combination of weights and x, plus bias\n",
    "            y_predicted = self.predict(X)\n",
    "\n",
    "            # compute the gap between true and predicted outputs.\n",
    "            diff = y - y_predicted\n",
    "            loss = SSE(y, y_predicted)\n",
    "            \n",
    "            # compute gradients\n",
    "            dm1 = (-2 / n_samples) * np.matmul(X.T, diff)\n",
    "            dm2 = (-2 / n_samples) * np.matmul(np.sin(self.m3*X).T, diff)\n",
    "            dm3 = (-2 / n_samples) * np.matmul((X *self.m2* np.cos(self.m3*X)).T, diff)  \n",
    "            db  = (-2 / n_samples) * np.sum(diff)\n",
    "            \n",
    "            # update parameters\n",
    "            self.m1  = self.m1 - self.lr * dm1\n",
    "            self.m2  = self.m2 - self.lr * dm2\n",
    "            self.m3  = self.m3 - self.lr * dm3\n",
    "            self.bias= self.bias -  self.lr * db\n",
    "            \n",
    "            # display the loss on the progress bar.\n",
    "            tq.set_postfix({\"Loss\":loss})\n",
    "            \n",
    "            record = self.parameters\n",
    "            record.append(loss)\n",
    "            history.append(record)\n",
    "            \n",
    "        #print(history)\n",
    "        #return history\n",
    "        return np.array(history)\n",
    "            \n",
    "    @property\n",
    "    def parameters(self):\n",
    "        return [self.bias[0], self.m1[0][0], self.m2[0][0], self.m3[0][0]]\n",
    "            \n",
    "    def predict(self, X):\n",
    "        y_predicted = self.bias + self.m1*X + self.m2*np.sin(self.m3*X)\n",
    "        return y_predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50a7e726",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-27T14:03:16.125031Z",
     "start_time": "2024-08-27T14:03:16.118826Z"
    },
    "execution": {
     "iopub.execute_input": "2024-08-25T15:23:53.518266Z",
     "iopub.status.busy": "2024-08-25T15:23:53.518138Z",
     "iopub.status.idle": "2024-08-25T15:23:53.530857Z",
     "shell.execute_reply": "2024-08-25T15:23:53.530642Z",
     "shell.execute_reply.started": "2024-08-25T15:23:53.518259Z"
    }
   },
   "outputs": [],
   "source": [
    "# here we don't need the explicit bias feature column\n",
    "xx = np.array(y21[['x1']])\n",
    "yy = np.expand_dims(y2.y, 1) \n",
    "y21.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26b718ec",
   "metadata": {},
   "source": [
    "### let's now build the model via Gradient Descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68830135",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-27T14:03:17.828470Z",
     "start_time": "2024-08-27T14:03:16.126122Z"
    },
    "execution": {
     "iopub.execute_input": "2024-08-25T15:23:53.531368Z",
     "iopub.status.busy": "2024-08-25T15:23:53.531117Z",
     "iopub.status.idle": "2024-08-25T15:23:54.393271Z",
     "shell.execute_reply": "2024-08-25T15:23:54.392998Z",
     "shell.execute_reply.started": "2024-08-25T15:23:53.531361Z"
    }
   },
   "outputs": [],
   "source": [
    "gdmodel = MySinusoidFitViaGD(learning_rate=0.0001, n_iters=15000)\n",
    "# fit the model and estimate the yhat values.\n",
    "history = gdmodel.fit(xx, yy)\n",
    "#get the learned parameters from the model.\n",
    "bias, w1, w2, w3 = gdmodel.parameters\n",
    "print(\"Bias = \", bias, \" m1 =\", w1, \" m2 =\", w2, \" m3 =\", w3)\n",
    "# use the model to predict the yhat values.\n",
    "yhat7 = gdmodel.predict(xx)\n",
    "# estimate the loss again and display\n",
    "loss = SSE(yy, yhat7)\n",
    "print (\"Loss =\", loss)\n",
    "\n",
    "# let's plot the params and loss.\n",
    "a1 = range(len(history))\n",
    "fig, (ax1, ax2) = plt.subplots(2, 1)\n",
    "fig.suptitle('Parameters & Loss')\n",
    "fig.set_figwidth(10)\n",
    "fig.set_figheight(5)\n",
    "\n",
    "ax1.plot(a1, history[:,0])\n",
    "ax1.plot(a1, history[:,1])\n",
    "ax1.plot(a1, history[:,2])\n",
    "ax1.plot(a1, history[:,3])\n",
    "ax1.legend(['Bias', 'm1', 'm2', 'm3'], loc='upper left')\n",
    "\n",
    "ax2.plot(a1, history[:,4])\n",
    "ax2.set_xlabel('Epochs')\n",
    "ax2.legend(['Loss'], loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5e40bb4",
   "metadata": {},
   "source": [
    "### let's visualize and compare the linear fits estimated by OLS and GD."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f49b720",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-27T14:03:17.912103Z",
     "start_time": "2024-08-27T14:03:17.829855Z"
    },
    "execution": {
     "iopub.execute_input": "2024-08-25T15:23:54.393706Z",
     "iopub.status.busy": "2024-08-25T15:23:54.393605Z",
     "iopub.status.idle": "2024-08-25T15:23:54.442001Z",
     "shell.execute_reply": "2024-08-25T15:23:54.441744Z",
     "shell.execute_reply.started": "2024-08-25T15:23:54.393697Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.plot(y2.x, y2.y, 'r+')\n",
    "yhat1 = predict(beta, y2.x)\n",
    "plt.plot(y2.x, yhat3, 'b-')\n",
    "plt.plot(y2.x, yhat7, 'g-')\n",
    "plt.ylabel('Stock Price')\n",
    "plt.xlabel('Time')\n",
    "plt.legend(['Stock Price', 'SinusoidFit+OLS', 'SinusoidFit+GD'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef1f76c9",
   "metadata": {},
   "source": [
    "### let's try doing the same using Tensorflow, where gradients are computed automatically.\n",
    "\n",
    "#### here, we don't have to hardcode the initial values.  The network learns all parameters automatically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c68e9f29",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-27T14:03:17.916605Z",
     "start_time": "2024-08-27T14:03:17.913759Z"
    },
    "execution": {
     "iopub.execute_input": "2024-08-25T15:24:01.306858Z",
     "iopub.status.busy": "2024-08-25T15:24:01.306648Z",
     "iopub.status.idle": "2024-08-25T15:24:01.310136Z",
     "shell.execute_reply": "2024-08-25T15:24:01.309673Z",
     "shell.execute_reply.started": "2024-08-25T15:24:01.306843Z"
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.layers import Activation\n",
    "from tensorflow.keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29f11f18",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-27T14:03:17.923385Z",
     "start_time": "2024-08-27T14:03:17.918164Z"
    },
    "execution": {
     "iopub.execute_input": "2024-08-25T15:24:03.345693Z",
     "iopub.status.busy": "2024-08-25T15:24:03.345486Z",
     "iopub.status.idle": "2024-08-25T15:24:03.350474Z",
     "shell.execute_reply": "2024-08-25T15:24:03.349969Z",
     "shell.execute_reply.started": "2024-08-25T15:24:03.345679Z"
    }
   },
   "outputs": [],
   "source": [
    "class ParameterizedSinusoid(layers.Layer):\n",
    "    def __init__(self, **kwargs):\n",
    "        super(ParameterizedSinusoid, self).__init__(**kwargs)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        # Create a trainable weight variable for this layer.\n",
    "        self.W = self.add_weight(shape=(1, input_shape[1]),\n",
    "                                 initializer='random_normal',\n",
    "                                 trainable=True)\n",
    "        super(ParameterizedSinusoid, self).build(input_shape)  # Be sure to call this somewhere!\n",
    "\n",
    "    def call(self, inputs):\n",
    "        # compute sin(Wx)\n",
    "        ax = tf.math.sin(tf.multiply(self.W, inputs))\n",
    "        return ax\n",
    "    \n",
    "class Sinusoid(layers.Layer):\n",
    "    def __init__(self, **kwargs):\n",
    "        super(Sinusoid, self).__init__(**kwargs)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        super(Sinusoid, self).build(input_shape)  # Be sure to call this somewhere!\n",
    "\n",
    "    def call(self, inputs):\n",
    "        # compute sin(x)\n",
    "        ax = tf.math.sin(inputs)\n",
    "        return ax"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2eb47fd",
   "metadata": {},
   "source": [
    "### let's create a custom activation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ea16093",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-27T14:03:17.931084Z",
     "start_time": "2024-08-27T14:03:17.924658Z"
    },
    "execution": {
     "iopub.execute_input": "2024-08-25T15:24:04.677866Z",
     "iopub.status.busy": "2024-08-25T15:24:04.677600Z",
     "iopub.status.idle": "2024-08-25T15:24:04.682179Z",
     "shell.execute_reply": "2024-08-25T15:24:04.681770Z",
     "shell.execute_reply.started": "2024-08-25T15:24:04.677839Z"
    }
   },
   "outputs": [],
   "source": [
    "# let's define a custom activation function \"sinusoid\"\n",
    "def sinusoid(x):\n",
    "    return tf.math.sin(x)\n",
    "\n",
    "from keras.utils import get_custom_objects\n",
    "get_custom_objects().update({'sinusoid': Activation(sinusoid)})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "615f4d45",
   "metadata": {},
   "source": [
    "### reload the dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "440a3728",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-27T14:03:18.715419Z",
     "start_time": "2024-08-27T14:03:17.932414Z"
    },
    "execution": {
     "iopub.execute_input": "2024-08-25T15:24:05.866429Z",
     "iopub.status.busy": "2024-08-25T15:24:05.866206Z",
     "iopub.status.idle": "2024-08-25T15:24:06.064982Z",
     "shell.execute_reply": "2024-08-25T15:24:06.064421Z",
     "shell.execute_reply.started": "2024-08-25T15:24:05.866413Z"
    }
   },
   "outputs": [],
   "source": [
    "#print(y2df.head())\n",
    "#yy = np.array(y2df.y) \n",
    "#xx = np.array(y2df[[\"x1\"]])  # no need for \"bias\", as our GD method factors it already.\n",
    "\n",
    "print(y21.head())\n",
    "yy = np.array(y21.y) \n",
    "xx = np.array(y21[[\"x1\"]])  # no need for \"bias\", as our GD method factors it already.\n",
    "reg_ds = tf.data.Dataset.from_tensor_slices((xx, yy)).batch(100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1689d66c",
   "metadata": {},
   "source": [
    "### create a neural network for the sinusoidal feature based regression fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c772f80d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-27T14:03:18.772485Z",
     "start_time": "2024-08-27T14:03:18.716402Z"
    },
    "execution": {
     "iopub.execute_input": "2024-08-25T15:25:42.468224Z",
     "iopub.status.busy": "2024-08-25T15:25:42.467435Z",
     "iopub.status.idle": "2024-08-25T15:25:42.496367Z",
     "shell.execute_reply": "2024-08-25T15:25:42.496005Z",
     "shell.execute_reply.started": "2024-08-25T15:25:42.468198Z"
    }
   },
   "outputs": [],
   "source": [
    "inputs = layers.Input((1,), dtype=tf.float32, name='input')\n",
    "d1 = layers.Dense(1, name='m3', activation=Activation(sinusoid), use_bias=False)(inputs)  # \"sinusoid\"\n",
    "d2 = layers.Dense(1, name='m1', use_bias=True)(inputs)\n",
    "d3 = layers.Dense(1, name='m2', use_bias=False)(d1)\n",
    "output = layers.add((d2, d3), name='output')\n",
    "model = tf.keras.Model(inputs, output, name='regressor')\n",
    "model.compile(optimizer = tf.keras.optimizers.Adam(learning_rate=0.0001), loss='mean_squared_error')\n",
    "model.summary()\n",
    "#visualkeras.graph_view(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfcd8f64",
   "metadata": {},
   "source": [
    "### layers visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85a1118c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-27T14:03:18.858482Z",
     "start_time": "2024-08-27T14:03:18.773615Z"
    },
    "execution": {
     "iopub.execute_input": "2024-08-25T15:25:43.901195Z",
     "iopub.status.busy": "2024-08-25T15:25:43.900963Z",
     "iopub.status.idle": "2024-08-25T15:25:43.962280Z",
     "shell.execute_reply": "2024-08-25T15:25:43.961682Z",
     "shell.execute_reply.started": "2024-08-25T15:25:43.901157Z"
    }
   },
   "outputs": [],
   "source": [
    "from keras.utils import plot_model\n",
    "plot_model(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d4b35b9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-14T06:06:59.143388Z",
     "start_time": "2024-08-14T06:06:59.134421Z"
    }
   },
   "source": [
    "### learn the network.  If the loss does not go below 10, restart training!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20d8b6ac",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-27T14:03:27.891534Z",
     "start_time": "2024-08-27T14:03:18.859762Z"
    },
    "execution": {
     "iopub.execute_input": "2024-08-25T15:26:18.409529Z",
     "iopub.status.busy": "2024-08-25T15:26:18.409322Z",
     "iopub.status.idle": "2024-08-25T15:26:23.582392Z",
     "shell.execute_reply": "2024-08-25T15:26:23.582023Z",
     "shell.execute_reply.started": "2024-08-25T15:26:18.409514Z"
    }
   },
   "outputs": [],
   "source": [
    "from tqdm.keras import TqdmCallback\n",
    "\n",
    "history = model.fit(reg_ds, epochs = 1000, verbose=0, callbacks=[TqdmCallback(verbose=0)])\n",
    "yhat8 = model.predict(reg_ds)\n",
    "\n",
    "plt.plot(history.history['loss'])\n",
    "plt.title('Loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "model.weights"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef99c52f",
   "metadata": {},
   "source": [
    "### plot and compare the fits through OLS and TF/GD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b741c117",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-27T14:03:27.969599Z",
     "start_time": "2024-08-27T14:03:27.892531Z"
    },
    "execution": {
     "iopub.execute_input": "2024-08-25T15:26:24.635624Z",
     "iopub.status.busy": "2024-08-25T15:26:24.635383Z",
     "iopub.status.idle": "2024-08-25T15:26:24.727729Z",
     "shell.execute_reply": "2024-08-25T15:26:24.727291Z",
     "shell.execute_reply.started": "2024-08-25T15:26:24.635608Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.plot(y2.x, y2.y, 'r+')\n",
    "yhat1 = predict(beta, y2.x)\n",
    "plt.plot(y2.x, yhat3, 'b-')\n",
    "plt.plot(y2.x, yhat8, 'g-')\n",
    "plt.ylabel('Stock Price')\n",
    "plt.xlabel('Time')\n",
    "plt.legend(['Stock Price', 'SinusoidFit+OLS', 'SinusoidFit+GD'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62264503",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-25T15:26:28.403867Z",
     "iopub.status.busy": "2024-08-25T15:26:28.403625Z",
     "iopub.status.idle": "2024-08-25T15:26:28.407832Z",
     "shell.execute_reply": "2024-08-25T15:26:28.407269Z",
     "shell.execute_reply.started": "2024-08-25T15:26:28.403852Z"
    }
   },
   "source": [
    "### let's try using locally weighted regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "425a8ed4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-25T15:54:22.453878Z",
     "iopub.status.busy": "2024-08-25T15:54:22.453523Z",
     "iopub.status.idle": "2024-08-25T15:54:22.459392Z",
     "shell.execute_reply": "2024-08-25T15:54:22.458671Z",
     "shell.execute_reply.started": "2024-08-25T15:54:22.453852Z"
    }
   },
   "source": [
    "Instead of fitting a single regression line, we find a nearest points to the given data point X using a kernel function (to compute weights) and fit the model for it, we do this for every single point, therfore this model results in smooth curve.\n",
    "\n",
    "$h(x_0) = x_0^\\top\\hat\\beta(x_0)$\n",
    "\n",
    "$\\hat\\beta(x_0)=\\arg\\min_\\beta\\sum_{x,y}w(x,x_0)(y-x^\\top\\beta)^2$\n",
    "\n",
    "$w(x,x_0)=\\exp\\left(-\\frac{\\|x-x_0\\|^2}{2\\tau^2}\\right)$\n",
    "\n",
    "$\\hat\\beta(x_0)=\\frac{X^\\top Wy}{X^\\top WX}$\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3be95837",
   "metadata": {},
   "source": [
    "__let's recall the dataset.  Let's use the scaled version of the 'x' axis__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "601b0417",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-27T14:14:25.473239Z",
     "start_time": "2024-08-27T14:14:25.468762Z"
    },
    "execution": {
     "iopub.execute_input": "2024-08-25T16:59:22.281134Z",
     "iopub.status.busy": "2024-08-25T16:59:22.280924Z",
     "iopub.status.idle": "2024-08-25T16:59:22.285023Z",
     "shell.execute_reply": "2024-08-25T16:59:22.284602Z",
     "shell.execute_reply.started": "2024-08-25T16:59:22.281119Z"
    }
   },
   "outputs": [],
   "source": [
    "# the LWR method works seamless for the original x values and the scaled version.\n",
    "# just that, we have to tune the \\tau value appropriately to handle the scale.\n",
    "yy = np.array(y21.y) \n",
    "xx = np.array(y21[[\"x\"]]).reshape((y21.shape[0],))  # no need for \"bias\", as our GD method factors it already."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "838d94b5",
   "metadata": {},
   "source": [
    "Given a dataset X, y, we attempt to find a model h(x) that minimizes residual sum of weighted squared errors. The weights are given by a kernel function $w^{(i)}=\\exp\\left(-\\frac{\\|x^{(i)}-x\\|^2}{2\\tau^2}\\right)$ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fbb2ccf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-27T14:04:25.452303Z",
     "start_time": "2024-08-27T14:04:25.449377Z"
    },
    "execution": {
     "iopub.execute_input": "2024-08-25T16:59:22.868129Z",
     "iopub.status.busy": "2024-08-25T16:59:22.867914Z",
     "iopub.status.idle": "2024-08-25T16:59:22.871793Z",
     "shell.execute_reply": "2024-08-25T16:59:22.871291Z",
     "shell.execute_reply.started": "2024-08-25T16:59:22.868113Z"
    }
   },
   "outputs": [],
   "source": [
    "def gaussian_kernel(xi,X,tau):\n",
    "    # compute the kernel distances\n",
    "    num = np.exp(-(xi-X)**2/(2*tau**2))\n",
    "    # normalize the distance\n",
    "    return num/np.sum(num)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a486a72a",
   "metadata": {},
   "source": [
    "Let's implement the LWR using $\\hat\\beta(x_0)=\\frac{X^\\top Wy}{X^\\top WX}$ for a data point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acfbb83c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-27T14:04:26.453497Z",
     "start_time": "2024-08-27T14:04:26.449498Z"
    },
    "execution": {
     "iopub.execute_input": "2024-08-25T16:59:23.576932Z",
     "iopub.status.busy": "2024-08-25T16:59:23.576725Z",
     "iopub.status.idle": "2024-08-25T16:59:23.580722Z",
     "shell.execute_reply": "2024-08-25T16:59:23.580220Z",
     "shell.execute_reply.started": "2024-08-25T16:59:23.576917Z"
    }
   },
   "outputs": [],
   "source": [
    "def LWR(xi, X, y, tau):\n",
    "    weights = gaussian_kernel(xi, X, tau)    \n",
    "    Phi = np.column_stack((np.ones(len(X)), X))\n",
    "    W = np.diag(weights)\n",
    "    theta = np.linalg.inv(Phi.T @ W @ Phi) @ Phi.T @ W @ y\n",
    "    return np.array([1,xi]) @ theta"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2cdb635",
   "metadata": {},
   "source": [
    "Predicting is a matter of repeating LWR for every point from the given test data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65e94998",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-27T14:04:27.289470Z",
     "start_time": "2024-08-27T14:04:27.285693Z"
    },
    "execution": {
     "iopub.execute_input": "2024-08-25T16:59:24.806705Z",
     "iopub.status.busy": "2024-08-25T16:59:24.806496Z",
     "iopub.status.idle": "2024-08-25T16:59:24.810804Z",
     "shell.execute_reply": "2024-08-25T16:59:24.810140Z",
     "shell.execute_reply.started": "2024-08-25T16:59:24.806690Z"
    }
   },
   "outputs": [],
   "source": [
    "def predict(X_test,X,y,tau=.1):\n",
    "    preds = np.zeros(X_test.shape[0])\n",
    "    for i in range(X_test.shape[0]):\n",
    "        preds[i] = LWR(X_test[i],X,y,tau)\n",
    "    return preds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c95b21f0",
   "metadata": {},
   "source": [
    "__changing the value of $\\tau$ alters the smoothness of the fit.  When the $\\tau$ is close to zero, the fit is wiggly and when it is high, the fit gets smoother and ultimately becomes a straight line fit__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7524ca42",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-27T14:09:53.670535Z",
     "start_time": "2024-08-27T14:09:53.640447Z"
    },
    "execution": {
     "iopub.execute_input": "2024-08-25T17:01:11.376008Z",
     "iopub.status.busy": "2024-08-25T17:01:11.375800Z",
     "iopub.status.idle": "2024-08-25T17:01:11.407870Z",
     "shell.execute_reply": "2024-08-25T17:01:11.407118Z",
     "shell.execute_reply.started": "2024-08-25T17:01:11.375993Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "y_preds = predict(xx,xx,yy,tau=2)\n",
    "loss = SSE(y_preds, yy)\n",
    "print(\"Loss =\", loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5699535f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-27T14:09:53.906298Z",
     "start_time": "2024-08-27T14:09:53.816462Z"
    },
    "execution": {
     "iopub.execute_input": "2024-08-25T17:01:11.681637Z",
     "iopub.status.busy": "2024-08-25T17:01:11.681426Z",
     "iopub.status.idle": "2024-08-25T17:01:11.772590Z",
     "shell.execute_reply": "2024-08-25T17:01:11.772009Z",
     "shell.execute_reply.started": "2024-08-25T17:01:11.681623Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.plot(xx, y2.y, 'r+')\n",
    "plt.plot(xx, yhat3, 'b-')\n",
    "plt.plot(xx, y_preds, 'k-')\n",
    "plt.ylabel('Stock Price')\n",
    "plt.xlabel('Time')\n",
    "plt.legend(['Stock Price', 'SinusoidFit+OLS', 'WeightedRegression'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6eee9588",
   "metadata": {},
   "source": [
    "### let's try the extrapolation usecase\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceeb5d90",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-27T14:13:35.021568Z",
     "start_time": "2024-08-27T14:13:35.018840Z"
    }
   },
   "outputs": [],
   "source": [
    "# our range is 0-225, let's stretch the range to do extrapolation.\n",
    "xx_extra = np.arange(0, 250, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aae4c818",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-27T14:08:39.133538Z",
     "start_time": "2024-08-27T14:08:39.016080Z"
    }
   },
   "outputs": [],
   "source": [
    "y_preds_extra = predict(xx_extra, xx, yy, tau=2)\n",
    "plt.plot(xx, y2.y, 'r+')\n",
    "plt.plot(xx, yhat3, 'b-')\n",
    "plt.plot(xx_extra, y_preds_extra, 'k-')\n",
    "plt.ylabel('Stock Price')\n",
    "plt.xlabel('Time')\n",
    "plt.legend(['Stock Price', 'SinusoidFit+OLS', 'WeightedRegression'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d137d0b",
   "metadata": {},
   "source": [
    "__clearly the extrapolation use is not working at all!!__\n",
    "\n",
    "Nonetheless, for interpolation usecases, the locally-weighted regression model would be of greater help.  If you look at the number of parameters learned during the prediction of training data, we see that there are 2 parameter per data points and hence 2 * N parameters in total.  But, to make a prediction for one test point, we learn the model using the weighted neighbors and make the prediction for the supplied input. So, technically, the behaviour is parameter-less!  Also, the LWR can be considered as a variation of the kNN (lazy modeling)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7b6bccf",
   "metadata": {},
   "source": [
    "When data is ${x_1, x_2, ..., x_m}$ and labels are ${y_1, y_2, ..., y_m}$, the dumbest estimate of output is given by $ y = \\frac{1}{m}\\sum_{i=1}^{m}y_i$.  A better way to modeling is to weight the labels according to the location (Watson, Nadaraya, 1964) as $y = \\sum_{i=1}^m \\alpha(x, x_i)y_i$, where $\\alpha$ can be modeled as a kernel function $k(x_i, x)$ such as Gaussian (see above for the Gaussian weighting function).  It is worthy to note that the formation is of the type Query, Key, Value (as in Transformers).  Here $x$ is the *Query*, $x_i$ is the *Key* and $y_i$ is the *Value*.  We may extend the weighting function by normalizing it into $\\alpha_i(x) = \\frac{k(x_i, x)}{\\sum_j k(x_j, x)}$. Using all the components the model of the regression line becomes $f(x) = \\sum_i y_i \\alpha_i(x) = \\sum_i y_i \\frac{k(x_i, x)}{\\sum_j k(x_j, x)}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a501c14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# implementing the above idea.\n",
    "def WReg(X_test, X, y, tau):\n",
    "    preds = []\n",
    "    for x_t in X_test:\n",
    "        num = gaussian_kernel(x_t, X, tau)\n",
    "        ratio = num / np.sum(num)\n",
    "        pred = np.sum(ratio * y)\n",
    "        preds.append(pred)\n",
    "    return np.array(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc1865ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# making predictions\n",
    "y_preds_v2 = WReg(xx,xx,yy,tau=2)\n",
    "loss = SSE(y_preds_v2, yy)\n",
    "print(\"Loss =\", loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ebb17bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot and compare\n",
    "plt.plot(xx, y2.y, 'r+')\n",
    "plt.plot(xx, y_preds, 'k-')\n",
    "plt.plot(xx, y_preds_v2, 'g-')\n",
    "plt.ylabel('Stock Price')\n",
    "plt.xlabel('Time')\n",
    "plt.legend(['Stock Price', 'WeightedRegression', 'WeightedRegression_v2'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b1d1e53",
   "metadata": {},
   "source": [
    "__The plots are identical for the same $\\tau$ setting into both approaches. Green line is on top of the Black line, FYI.__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c66cdbc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "da5401",
   "language": "python",
   "name": "da5401"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
